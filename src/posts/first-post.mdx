---
title: 'Automatisierte Fragebogenentwicklung'
date: '2025-03-26'
excerpt: 'Wie Fragebogen-Items mithilfe von LLMs automatisch generiert und validiert werden können'
---

# KI-gestütztes Tool zur Fragebogenentwicklung: Ein innovativer Ansatz für HR und Organisationspsychologie

*Ein Freizeitprojekt zur Effizienzsteigerung in der psychometrischen Fragebogenentwicklung durch moderne KI-Technologien*

![AI Tool Screenshot](/images/blog/ai-tool1.gif)

## Die Herausforderung der Fragebogenentwicklung

Die Entwicklung qualitativ hochwertiger Fragebögen stellt für viele Organisationen eine erhebliche Herausforderung dar. 
Besonders in kleineren Unternehmen ohne spezialisierte Fachkräfte im Bereich Psychometrie sind Zeit, Ressourcen und methodisches Know-how oft begrenzt. 
Ob Mitarbeiterbefragung, Self-Assessment oder 360-Grad-Feedback – der traditionelle Entwicklungsprozess erfordert umfangreiche Expertise und durchläuft zahlreiche zeitintensive Phasen:

- Präzise Definition der zu messenden Konstrukte
- Systematische Entwicklung geeigneter Fragen (Items)
- Umfangreiche Pilottests mit Testpersonen
- Statistische Analysen zur Überprüfung der Qualität
- Mehrfache Überarbeitungsschleifen

## Innovation durch KI-Unterstützung

Die aktuelle Forschung zeigt vielversprechende Möglichkeiten, die frühen Phasen der Fragebogenentwicklung effizienter zu gestalten, ohne methodische Standards zu vernachlässigen. 
Das hier vorgestellte Tool setzt genau an diesem Punkt an und nutzt moderne Technologien, um den Prozess der Itemgenerierung und -validierung zu optimieren.

## Kernfunktionen des Tools

Das entwickelte Tool unterstützt HR-Fachkräfte, Berater:innen und Organisationspsycholog:innen durch folgende Funktionen:

### 1. KI-gestützte Itemgenerierung
- Automatische Erstellung von Items basierend auf Konstruktbeschreibungen
- Nutzung der Claude API für hochwertige, kontextsensitive Formulierungen
- Integration selbst entwickelter Items möglich

### 2. Qualitätssicherung
- Automatische Prüfung auf Best Practices der Itemformulierung
- Berücksichtigung psychometrischer Grundprinzipien
- Möglichkeit zur Entwicklung von Items, die für den Beruf kontextualisiert sind

### 3. Semantische Analyse
- Erstellung von Embeddings der generierten Items mittels BERT & sBERT
- Berechnung semantischer Ähnlichkeiten zwischen Items und Konstruktdefinitionen 
- Identifikation inhaltlicher Überlappungen und Abweichungen
- Unterstützung bei der Auswahl geeigneter Items

### 4. Vorläufige Strukturanalyse ohne Datenerhebung
- Schätzung & Visualisierung von Item-Zusammenhängen
- Vorläufige Faktorstrukturanalyse zur Identifikation suboptimaler Items
- Frühzeitige Erkennung potenzieller Probleme vor der eigentlichen Datenerhebung

## Anwendungsbeispiel: Verträglichkeitsskala

Ein praktisches Beispiel zur Veranschaulichung der Funktionsweise zeigt die Entwicklung einer Skala zur Messung der Persönlichkeitseigenschaft "Verträglichkeit":

1. Es fällt mir leicht, mich in die Gefühle anderer hineinzuversetzen.
2. Mir fällt es schwer, anderen Menschen zu vertrauen. (-)
3. Ich habe mit anderen wenig Mitgefühl. (-)
4. Ich zeige Verständnis, auch wenn andere eine andere Sicht der Dinge haben.
5. Ich bin anderen gegenüber misstrauisch. (-)
6. Die Sorgen anderer Menschen berühren mich kaum. (-)
7. Ich bin nachsichtig, vergebe anderen leicht.

*Items mit (-) sind Indikatoren für niedrige Verträglichkeit.*

Die besondere Herausforderung: Können Sie erkennen, welche Items vom Menschen und welche vom Tool erstellt wurden?

## Wissenschaftliche Grundlage

Das Tool basiert auf aktueller Forschung im Bereich der KI-gestützten Fragebogenentwicklung:

- Guenole et al. (2024) haben wegweisende Methoden zur automatisierten Itemgenerierung vorgestellt
- Hommel & Arslan (2024) zeigen Möglichkeiten zur Evaluation semantischer Kohärenz ohne umfangreiche Datenerhebung auf

## Wichtige Einschränkungen

Das Tool verfolgt einen "Human-in-the-Loop"-Ansatz und ist explizit als Unterstützung für die erste Phase der Itementwicklung konzipiert. Es ersetzt nicht:

- Die kritische Beurteilung durch Fachexpert:innen
- Die empirische Validierung mit Zielgruppen
- Die notwendige Überarbeitung basierend auf tatsächlichen Daten

Die eingesetzten Methoden zeigen vielversprechende Ergebnisse, befinden sich jedoch noch in einem Entwicklungsstadium und bedürfen weiterer wissenschaftlicher Validierung.

## Nutzen und Potenzial

Der Mehrwert des Tools liegt besonders in folgenden Bereichen:

- **Zeitersparnis**: Beschleunigung der ersten Entwicklungsphase durch automatisierte Itemgenerierung
- **Qualitätsverbesserung**: Systematische Überprüfung auf psychometrische Best Practices
- **Methodische Unterstützung**: Hilfestellung für Teams ohne spezialisierte psychometrische Expertise
- **Frühzeitige Optimierung**: Identifikation potenzieller Probleme vor der aufwändigen Datenerhebung

## Ausblick und Feedback

Als Freizeitprojekt befindet sich das Tool in kontinuierlicher Weiterentwicklung. Feedback von Praktiker:innen und Expert:innen ist ausdrücklich erwünscht! Besonders interessant sind Erfahrungsberichte zur praktischen Anwendbarkeit und Vorschläge zur Erweiterung der Funktionalität.

---

**Über den Entwickler**: *[Hier könnte eine kurze Beschreibung des Entwicklers stehen, falls gewünscht]*

**Kontakt**: *[Kontaktinformationen, falls gewünscht]*

**Quellen**:
- Guenole, N. et al. (2024). [Titel der Publikation zur automatisierten Itemgenerierung]
- Hommel, B. & Arslan, R. (2024). [Titel der Publikation zur semantischen Evaluation]

### Pseudo-Faktorenanalyse
#### Traditioneller Ansatz

Abc 

#### Kosinus-Ähnlichkeit und Pearson-Korrelation
Wir betrachten zwei Vektoren 
$$
x = (x_1, x_2, \dots, x_n), \quad y = (y_1, y_2, \dots, y_n).
$$

##### Schritt 1: Berechnung der Mittelwerte
Berechne den Mittelwert der Komponenten von $$ x $$ und $$ y $$:

$$
\bar{x} = \frac{1}{n}\sum_{i=1}^n x_i, \quad \bar{y} = \frac{1}{n}\sum_{i=1}^n y_i.
$$

##### Schritt 2: Zentrieren der Vektoren
Definiere die zentrierten Vektoren, indem du von jedem Element den Mittelwert abziehst:

$$
\tilde{x} = x - \bar{x} = (x_1 - \bar{x}, \dots, x_n - \bar{x}), \quad \tilde{y} = y - \bar{y} = (y_1 - \bar{y}, \dots, y_n - \bar{y}).
$$

##### Schritt 3: Definition der Pearson-Korrelation
Die Pearson-Korrelation $$r$$ wird definiert als

$$
r = \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum_{i=1}^n (x_i - \bar{x})^2}\sqrt{\sum_{i=1}^n (y_i - \bar{y})^2}}.
$$

Beachte, dass der Zähler dem Skalarprodukt der zentrierten Vektoren entspricht:

$$
\sum_{i=1}^n (x_i-\bar{x})(y_i-\bar{y}) = \tilde{\mathbf{x}} \cdot \tilde{\mathbf{y}},
$$

und die Nenner den euklidischen Normen der zentrierten Vektoren:

$$
\|\tilde{\mathbf{x}}\| = \sqrt{\sum_{i=1}^n (x_i-\bar{x})^2}, \quad \|\tilde{\mathbf{y}}\| = \sqrt{\sum_{i=1}^n (y_i-\bar{y})^2}.
$$

Somit kann man schreiben:

$$
r = \frac{\tilde{\mathbf{x}} \cdot \tilde{\mathbf{y}}}{\|\tilde{\mathbf{x}}\| \, \|\tilde{\mathbf{y}}\|}.
$$

##### Schritt 4: Definition der Cosinus-Ähnlichkeit
Die Cosinus-Ähnlichkeit zwischen zwei Vektoren $$a$$ und $$b$$ ist definiert als

$$
\cos(\theta) = \frac{\mathbf{a} \cdot \mathbf{b}}{\|\mathbf{a}\|\,\|\mathbf{b}\|}.
$$

Setzen wir hier die zentrierten Vektoren $$\tilde{x}$$ und $$\tilde{y}$$ ein, erhalten wir:

$$
\cos(\theta_{\text{zentriert}}) = \frac{\tilde{\mathbf{x}} \cdot \tilde{\mathbf{y}}}{\|\tilde{\mathbf{x}}\|\,\|\tilde{\mathbf{y}}\|}.
$$

##### Schritt 5: Vergleich der beiden Ausdrücke
Wir vergleichen die beiden Gleichungen:

$$
r = \frac{\tilde{\mathbf{x}} \cdot \tilde{\mathbf{y}}}{\|\tilde{\mathbf{x}}\|\,\|\tilde{\mathbf{y}}\|}, \quad \cos(\theta_{\text{zentriert}}) = \frac{\tilde{\mathbf{x}} \cdot \tilde{\mathbf{y}}}{\|\tilde{\mathbf{x}}\|\,\|\tilde{\mathbf{y}}\|}.
$$

Da beide Ausdrücke identisch sind, folgt: $$ r = \cos(\theta_{\text{zentriert}}). $$

Die Pearson-Korrelation entspricht der Cosinus-Ähnlichkeit, wenn die Daten vorher zentriert werden. Dadurch wird deutlich, dass der Pearson-Korrelationskoeffizient als eine zentrierte Variante der Cosinus-Ähnlichkeit verstanden werden kann.